# -*- coding: utf-8 -*-
"""U5L2D4 - API_with_Scrapy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wLf3U414bvov4M97ZDpayQEsVjqFTz7S

# Scraping Coinmarketcap

I'll will scrape the URL: https://coinmarketcap.com/all/views/all/. This website contains information about cryptocurrencies such as their current prices, circulation supply, volume, etc.
"""

# import libraries
import re
import scrapy
from scrapy.crawler import CrawlerProcess

# create a spider
class coinSpider(scrapy.Spider):
    # naming the spider
    name = "coinSpider"
    
    # URL to start with.
    start_url = ['https://coinmarketcap.com/all/views/all/']

    # XPath to parse the response
    def parse(self, response):
        # iterate over every <tr> element in the tbody section.
        for row in response.xpath('.//tbody/tr'):
            yield {
                # This is the code to choose what we want to extract
                # You can modify this with other Xpath expressions to extract other information from the site
                'name': row.xpath('td[2]/a/text()').extract_first(),
                'price': row.xpath('td[5]/a/text()').extract_first(),
                'supply': row.xpath('td[6]/span/text()').extract_first(),
                'volume': row.xpath('td[7]/a/text()').extract_first()
                  }

# defining parameters for crawler
process = CrawlerProcess({
    'FEED_FORMAT': 'json',         # store data in JSON format
    'FEED_URI': 'coins_market.json',  # same the storage file
    'LOG_ENABLED': False           # turn off logging
})

# start the crawler with spider.
process.crawl(coinSpider)
process.start()
print('Done!')

